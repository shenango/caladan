From b8686ff93db9873375cf746834eab9f7b339ebe1 Mon Sep 17 00:00:00 2001
From: Josh Fried <joshuafried@gmail.com>
Date: Mon, 24 Apr 2023 20:43:53 -0400
Subject: [PATCH 3/5] enable fast flow steering in vfio mode

implement *just enough* of required functionality in the vfio
driver to support direct rules (in our use case).
---
 providers/mlx5/CMakeLists.txt |   2 +
 providers/mlx5/dr_devx.c      |   4 +
 providers/mlx5/dr_domain.c    |  12 +-
 providers/mlx5/dr_table.c     |   5 +
 providers/mlx5/libmlx5.map    |   1 +
 providers/mlx5/mlx5_ifc.h     | 134 ++++++++++-
 providers/mlx5/mlx5_vfio.c    |  41 +++-
 providers/mlx5/mlx5_vfio.h    |  69 ++++++
 providers/mlx5/mlx5_vfio_dm.c | 429 ++++++++++++++++++++++++++++++++++
 providers/mlx5/mlx5_vfio_dr.c | 154 ++++++++++++
 providers/mlx5/mlx5dv.h       |   2 +
 providers/mlx5/mlx5dv_dr.h    |   7 +-
 util/bitmap.c                 |  20 ++
 util/bitmap.h                 |   6 +
 14 files changed, 871 insertions(+), 15 deletions(-)
 create mode 100644 providers/mlx5/mlx5_vfio_dm.c
 create mode 100644 providers/mlx5/mlx5_vfio_dr.c

diff --git a/providers/mlx5/CMakeLists.txt b/providers/mlx5/CMakeLists.txt
index c2ca7a82..9d350ba9 100644
--- a/providers/mlx5/CMakeLists.txt
+++ b/providers/mlx5/CMakeLists.txt
@@ -35,6 +35,8 @@ rdma_shared_provider(mlx5 libmlx5.map
   dr_arg.c
   mlx5.c
   mlx5_vfio.c
+  mlx5_vfio_dm.c
+  mlx5_vfio_dr.c
   qp.c
   srq.c
   verbs.c
diff --git a/providers/mlx5/dr_devx.c b/providers/mlx5/dr_devx.c
index 3f81cda0..0d58024e 100644
--- a/providers/mlx5/dr_devx.c
+++ b/providers/mlx5/dr_devx.c
@@ -996,6 +996,10 @@ struct mlx5dv_devx_obj *dr_devx_create_qp(struct ibv_context *ctx,
 	DEVX_SET(qpc, qpc, isolate_vl_tc, attr->isolate_vl_tc);
 	DEVX_SET(qpc, qpc, ts_format, attr->qp_ts_format);
 
+	// Kernel driver sets these for us, but we need to do it for VFIO mode.
+	DEVX_SET(qpc, qpc, dbr_umem_valid, 1);
+	DEVX_SET(create_qp_in, in, wq_umem_valid, 1);
+
 	DEVX_SET(create_qp_in, in, wq_umem_id, attr->buff_umem_id);
 
 	obj = mlx5dv_devx_obj_create(ctx, in, sizeof(in), out, sizeof(out));
diff --git a/providers/mlx5/dr_domain.c b/providers/mlx5/dr_domain.c
index df9c83c3..b0375ee3 100644
--- a/providers/mlx5/dr_domain.c
+++ b/providers/mlx5/dr_domain.c
@@ -276,11 +276,18 @@ static bool dr_domain_caps_is_sw_owner_supported(bool sw_owner,
 static int dr_domain_caps_init(struct ibv_context *ctx,
 			       struct mlx5dv_dr_domain *dmn)
 {
+	struct ibv_device_attr_ex attr;
 	struct ibv_port_attr port_attr = {};
 	int ret;
 
 	dmn->info.caps.dmn = dmn;
 
+	/*
+	 * vfio driver includes limited support for ibv_query_port and
+	 * ibv_query_device_ex. extract only the supported fields here. if other
+	 * fields are needed in the future, the vfio driver must add support for
+	 * them.
+	 */
 	ret = ibv_query_port(ctx, 1, &port_attr);
 	if (ret) {
 		dr_dbg(dmn, "Failed to query port\n");
@@ -293,9 +300,12 @@ static int dr_domain_caps_init(struct ibv_context *ctx,
 		return errno;
 	}
 
-	ret = ibv_query_device_ex(ctx, NULL, &dmn->info.attr);
+	ret = ibv_query_device_ex(ctx, NULL, &attr);
 	if (ret)
 		return ret;
+	dmn->info.attr.phys_port_cnt_ex = attr.phys_port_cnt_ex;
+	memcpy(dmn->info.attr.orig_attr.fw_ver, attr.orig_attr.fw_ver,
+		sizeof(attr.orig_attr.fw_ver));
 
 	ret = dr_devx_query_device(ctx, &dmn->info.caps);
 	if (ret)
diff --git a/providers/mlx5/dr_table.c b/providers/mlx5/dr_table.c
index af4907d1..7e9bb12a 100644
--- a/providers/mlx5/dr_table.c
+++ b/providers/mlx5/dr_table.c
@@ -163,6 +163,11 @@ static int dr_table_create_devx_tbl(struct mlx5dv_dr_table *tbl)
 	return 0;
 }
 
+uint32_t mlx5dv_dr_table_get_id(struct mlx5dv_dr_table *tbl)
+{
+	return tbl->devx_obj->object_id;
+}
+
 struct mlx5dv_dr_table *mlx5dv_dr_table_create(struct mlx5dv_dr_domain *dmn,
 					     uint32_t level)
 {
diff --git a/providers/mlx5/libmlx5.map b/providers/mlx5/libmlx5.map
index 2ba9c69f..375d2b38 100644
--- a/providers/mlx5/libmlx5.map
+++ b/providers/mlx5/libmlx5.map
@@ -238,4 +238,5 @@ MLX5_1.24 {
 		mlx5_vfio_deliver_event;
 		mlx5_vfio_get_clock;
 		mlx5_access_reg;
+		mlx5dv_dr_table_get_id;
 } MLX5_1.23;
diff --git a/providers/mlx5/mlx5_ifc.h b/providers/mlx5/mlx5_ifc.h
index 9acbe010..8d88c251 100644
--- a/providers/mlx5/mlx5_ifc.h
+++ b/providers/mlx5/mlx5_ifc.h
@@ -35,6 +35,15 @@
 
 #define u8 uint8_t
 
+enum {
+	MLX5_OBJ_TYPE_SW_ICM = 0x0008,
+};
+
+enum {
+	MLX5_GENERAL_OBJ_TYPES_CAP_SW_ICM = (1ULL << MLX5_OBJ_TYPE_SW_ICM),
+};
+
+
 enum mlx5_cap_mode {
 	HCA_CAP_OPMOD_GET_MAX = 0,
 	HCA_CAP_OPMOD_GET_CUR	= 1,
@@ -1526,11 +1535,34 @@ struct mlx5_ifc_query_hca_cap_in_bits {
 };
 
 enum mlx5_cap_type {
-	MLX5_CAP_GENERAL = 0,
-	MLX5_CAP_ODP = 2,
-	MLX5_CAP_ATOMIC = 3,
-	MLX5_CAP_ROCE,
-	MLX5_CAP_NUM,
+       MLX5_CAP_GENERAL = 0,
+       MLX5_CAP_ETHERNET_OFFLOADS,
+       MLX5_CAP_ODP = 2,
+       MLX5_CAP_ATOMIC = 3,
+       MLX5_CAP_ROCE,
+       MLX5_CAP_IPOIB_OFFLOADS,
+       MLX5_CAP_IPOIB_ENHANCED_OFFLOADS,
+       MLX5_CAP_FLOW_TABLE,
+       MLX5_CAP_ESWITCH_FLOW_TABLE,
+       MLX5_CAP_ESWITCH,
+       MLX5_CAP_RESERVED,
+       MLX5_CAP_VECTOR_CALC,
+       MLX5_CAP_QOS,
+       MLX5_CAP_DEBUG,
+       MLX5_CAP_RESERVED_14,
+       MLX5_CAP_DEV_MEM,
+       MLX5_CAP_RESERVED_16,
+       MLX5_CAP_TLS,
+       MLX5_CAP_VDPA_EMULATION = 0x13,
+       MLX5_CAP_DEV_EVENT = 0x14,
+       MLX5_CAP_IPSEC,
+       MLX5_CAP_DEV_SHAMPO = 0x1d,
+       MLX5_CAP_MACSEC = 0x1f,
+       MLX5_CAP_GENERAL_2 = 0x20,
+       MLX5_CAP_PORT_SELECTION = 0x25,
+       MLX5_CAP_ADV_VIRTUALIZATION = 0x26,
+       /* NUM OF CAP Types */
+       MLX5_CAP_NUM
 };
 
 enum {
@@ -1546,8 +1578,12 @@ enum {
 };
 
 enum {
-	MLX5_MKC_ACCESS_MODE_MTT = 0x1,
-	MLX5_MKC_ACCESS_MODE_KLMS = 0x2,
+	MLX5_MKC_ACCESS_MODE_PA    = 0x0,
+	MLX5_MKC_ACCESS_MODE_MTT   = 0x1,
+	MLX5_MKC_ACCESS_MODE_KLMS  = 0x2,
+	MLX5_MKC_ACCESS_MODE_KSM   = 0x3,
+	MLX5_MKC_ACCESS_MODE_SW_ICM = 0x4,
+	MLX5_MKC_ACCESS_MODE_MEMIC = 0x5,
 };
 
 struct mlx5_ifc_mkc_bits {
@@ -3250,6 +3286,26 @@ struct mlx5_ifc_general_obj_in_cmd_hdr_bits {
 	u8         reserved_at_68[0x18];
 };
 
+
+struct mlx5_ifc_sw_icm_bits {
+	u8         modify_field_select[0x40];
+
+	u8	   reserved_at_40[0x18];
+	u8         log_sw_icm_size[0x8];
+
+	u8         reserved_at_60[0x20];
+
+	u8         sw_icm_start_addr[0x40];
+
+	u8         reserved_at_c0[0x140];
+};
+
+struct mlx5_ifc_create_sw_icm_in_bits {
+	struct mlx5_ifc_general_obj_in_cmd_hdr_bits   hdr;
+	struct mlx5_ifc_sw_icm_bits		      sw_icm;
+};
+
+
 struct mlx5_ifc_general_obj_out_cmd_hdr_bits {
 	u8         status[0x8];
 	u8         reserved_at_8[0x18];
@@ -5116,6 +5172,70 @@ struct mlx5_ifc_delete_fte_in_bits {
 	u8         reserved_at_120[0xe0];
 };
 
+struct mlx5_ifc_cqc_bits {
+	u8 status[0x4];
+	u8 as_notify[0x1];
+	u8 initiator_src_dct[0x1];
+	u8 dbr_umem_valid[0x1];
+	u8 reserved_at_7[0x1];
+	u8 cqe_sz[0x3];
+	u8 cc[0x1];
+	u8 reserved_at_c[0x1];
+	u8 scqe_break_moderation_en[0x1];
+	u8 oi[0x1];
+	u8 cq_period_mode[0x2];
+	u8 cqe_comp_en[0x1];
+	u8 mini_cqe_res_format[0x2];
+	u8 st[0x4];
+	u8 reserved_at_18[0x1];
+	u8 cqe_comp_layout[0x7];
+	u8 dbr_umem_id[0x20];
+	u8 reserved_at_40[0x14];
+	u8 page_offset[0x6];
+	u8 reserved_at_5a[0x2];
+	u8 mini_cqe_res_format_ext[0x2];
+	u8 cq_timestamp_format[0x2];
+	u8 reserved_at_60[0x3];
+	u8 log_cq_size[0x5];
+	u8 uar_page[0x18];
+	u8 reserved_at_80[0x4];
+	u8 cq_period[0xc];
+	u8 cq_max_count[0x10];
+	u8 reserved_at_a0[0x18];
+	u8 c_eqn[0x8];
+	u8 reserved_at_c0[0x3];
+	u8 log_page_size[0x5];
+	u8 reserved_at_c8[0x18];
+	u8 reserved_at_e0[0x20];
+	u8 reserved_at_100[0x8];
+	u8 last_notified_index[0x18];
+	u8 reserved_at_120[0x8];
+	u8 last_solicit_index[0x18];
+	u8 reserved_at_140[0x8];
+	u8 consumer_counter[0x18];
+	u8 reserved_at_160[0x8];
+	u8 producer_counter[0x18];
+	u8 local_partition_id[0xc];
+	u8 process_id[0x14];
+	u8 reserved_at_1A0[0x20];
+	u8 dbr_addr[0x40];
+};
+
+struct mlx5_ifc_create_cq_in_bits {
+	u8 opcode[0x10];
+	u8 uid[0x10];
+	u8 reserved_at_20[0x10];
+	u8 op_mod[0x10];
+	u8 reserved_at_40[0x40];
+	struct mlx5_ifc_cqc_bits cq_context;
+	u8 cq_umem_offset[0x40];
+	u8 cq_umem_id[0x20];
+	u8 cq_umem_valid[0x1];
+	u8 reserved_at_2e1[0x1f];
+	u8 reserved_at_300[0x580];
+	u8 pas[];
+};
+
 struct mlx5_ifc_create_cq_out_bits {
 	u8         reserved_at_0[0x40];
 
diff --git a/providers/mlx5/mlx5_vfio.c b/providers/mlx5/mlx5_vfio.c
index 7f24b270..ecb38e05 100644
--- a/providers/mlx5/mlx5_vfio.c
+++ b/providers/mlx5/mlx5_vfio.c
@@ -785,7 +785,7 @@ end:
 	return err;
 }
 
-static int mlx5_vfio_cmd_exec(struct mlx5_vfio_context *ctx, void *in,
+int mlx5_vfio_cmd_exec(struct mlx5_vfio_context *ctx, void *in,
 			       int ilen, void *out, int olen,
 			       unsigned int slot)
 {
@@ -1877,7 +1877,7 @@ static int mlx5_vfio_nic_vport_update_roce_state(struct mlx5_vfio_context *ctx,
 	return err;
 }
 
-static int mlx5_vfio_get_caps(struct mlx5_vfio_context *ctx, enum mlx5_cap_type cap_type)
+int mlx5_vfio_get_caps(struct mlx5_vfio_context *ctx, enum mlx5_cap_type cap_type)
 {
 	int ret;
 
@@ -2782,13 +2782,23 @@ static int vfio_init_obj(struct mlx5dv_obj *obj, uint64_t obj_type)
 {
 	struct ibv_pd *pd_in = obj->pd.in;
 	struct mlx5dv_pd *pd_out = obj->pd.out;
-	struct mlx5_pd *mpd = to_mpd(pd_in);
+	struct mlx5_pd *mpd;
 
-	if (obj_type != MLX5DV_OBJ_PD)
+	if (obj_type & MLX5DV_OBJ_CQ) {
+		*obj->cq.out = container_of(obj->cq.in, struct mlx5_vfio_cq, cq_handle)->cq;
+		obj_type &= ~MLX5DV_OBJ_CQ;
+	}
+
+	if (obj_type & MLX5DV_OBJ_PD) {
+		mpd = to_mpd(pd_in);
+		pd_out->comp_mask = 0;
+		pd_out->pdn = mpd->pdn;
+		obj_type &= ~MLX5DV_OBJ_PD;
+	}
+
+	if (obj_type)
 		return EOPNOTSUPP;
 
-	pd_out->comp_mask = 0;
-	pd_out->pdn = mpd->pdn;
 	return 0;
 }
 
@@ -3139,6 +3149,8 @@ vfio_devx_obj_create(struct ibv_context *context, const void *in,
 	struct mlx5_vfio_context *ctx = to_mvfio_ctx(context);
 	struct mlx5_devx_obj *obj;
 	int ret;
+	uint16_t opcode;
+	uint64_t rx_icm_addr;
 
 	if (!devx_is_obj_create_cmd(in)) {
 		errno = EINVAL;
@@ -3161,6 +3173,15 @@ vfio_devx_obj_create(struct ibv_context *context, const void *in,
 				   &obj->dinlen, &obj->dv_obj);
 	obj->dv_obj.context = context;
 
+	opcode = DEVX_GET(general_obj_in_cmd_hdr, in, opcode);
+	if (opcode == MLX5_CMD_OP_CREATE_TIR) {
+		rx_icm_addr = DEVX_GET(create_tir_out, out, icm_address_31_0);
+		rx_icm_addr |= (uint64_t)DEVX_GET(create_tir_out, out, icm_address_39_32) << 32;
+		rx_icm_addr |= (uint64_t)DEVX_GET(create_tir_out, out, icm_address_63_40) << 40;
+		obj->dv_obj.rx_icm_addr = rx_icm_addr;
+		obj->dv_obj.type = MLX5_DEVX_TIR;
+	}
+
 	return &obj->dv_obj;
 fail:
 	free(obj);
@@ -3409,6 +3430,7 @@ static struct mlx5_dv_context_ops mlx5_vfio_dv_ctx_ops = {
 	.devx_free_msi_vector = vfio_devx_free_msi_vector,
 	.devx_create_eq = vfio_devx_create_eq,
 	.devx_destroy_eq = vfio_devx_destroy_eq,
+	.alloc_dm = mlx5_vfio_alloc_dm,
 };
 
 static void mlx5_vfio_uninit_context(struct mlx5_vfio_context *ctx)
@@ -3438,6 +3460,10 @@ static const struct verbs_context_ops mlx5_vfio_common_ops = {
 	.reg_mr = mlx5_vfio_reg_mr,
 	.dereg_mr = mlx5_vfio_dereg_mr,
 	.free_context = mlx5_vfio_free_context,
+	.create_cq = mlx5_vfio_create_cq,
+	.reg_dm_mr = mlx5_vfio_reg_dm_mr,
+	.query_device_ex = mlx5_vfio_query_device_ex,
+	.query_port = mlx5_vfio_query_port,
 };
 
 static struct verbs_context *
@@ -3472,6 +3498,9 @@ mlx5_vfio_alloc_context(struct ibv_device *ibdev,
 	if (mlx5_vfio_setup_function(mctx))
 		goto clean_cmd;
 
+	if (mlx5_vfio_dm_init(mctx))
+		mlx5_vfio_dv_ctx_ops.alloc_dm = NULL;
+
 	if (create_async_eqs(mctx))
 		goto func_teardown;
 
diff --git a/providers/mlx5/mlx5_vfio.h b/providers/mlx5/mlx5_vfio.h
index 6c3a7f34..23095f51 100644
--- a/providers/mlx5/mlx5_vfio.h
+++ b/providers/mlx5/mlx5_vfio.h
@@ -48,6 +48,37 @@ struct mlx5_vfio_mr {
 	uint64_t iova_reg_size;
 };
 
+extern int mlx5_vfio_query_device_ex(struct ibv_context *context,
+			 const struct ibv_query_device_ex_input *input,
+			 struct ibv_device_attr_ex *attr,
+			 size_t attr_size);
+extern int mlx5_vfio_query_port(struct ibv_context *context, uint8_t port,
+		     struct ibv_port_attr *attr);
+
+struct mlx5_vfio_context;
+extern int mlx5_vfio_dm_init(struct mlx5_vfio_context *ctx);
+extern struct ibv_dm *mlx5_vfio_alloc_dm(struct ibv_context *ibctx,
+				   struct ibv_alloc_dm_attr *dm_attr,
+				   struct mlx5dv_alloc_dm_attr *mlx5_dm_attr);
+extern int mlx5_vfio_get_caps(struct mlx5_vfio_context *ctx, enum mlx5_cap_type cap_type);
+extern int mlx5_vfio_cmd_exec(struct mlx5_vfio_context *ctx, void *in,
+			       int ilen, void *out, int olen,
+			       unsigned int slot);
+extern struct ibv_mr *mlx5_vfio_reg_dm_mr(struct ibv_pd *pd, struct ibv_dm *ibdm,
+			      uint64_t dm_offset, size_t length,
+			      unsigned int acc);
+
+extern struct ibv_cq *mlx5_vfio_create_cq(struct ibv_context *ibctx, int cqe,
+			     struct ibv_comp_channel *channel,
+			     int comp_vector);
+
+struct mlx5_vfio_cq {
+	struct mlx5dv_cq cq;
+	struct mlx5dv_devx_umem *mem_reg;
+	struct ibv_cq cq_handle;
+	struct mlx5dv_devx_obj *obj;
+};
+
 struct mlx5_vfio_devx_umem {
 	struct mlx5dv_devx_umem dv_devx_umem;
 	struct ibv_context *context;
@@ -91,6 +122,34 @@ struct mlx5_vfio_device {
 #define MLX5_VFIO_CAP_ROCE_MAX(ctx, cap) \
 	DEVX_GET(roce_cap, ctx->caps.hca_max[MLX5_CAP_ROCE], cap)
 
+#define MLX5_VFIO_CAP_DEV_MEM(ctx, cap)\
+	DEVX_GET(device_mem_cap, ctx->caps.hca_cur[MLX5_CAP_DEV_MEM], cap)
+
+#define MLX5_VFIO_CAP64_DEV_MEM(ctx, cap)\
+	DEVX_GET64(device_mem_cap, ctx->caps.hca_cur[MLX5_CAP_DEV_MEM], cap)
+
+
+#define MLX5_VFIO_CAP_FLOWTABLE(mdev, cap) \
+    DEVX_GET(flow_table_nic_cap, mdev->caps.hca_cur[MLX5_CAP_FLOW_TABLE], cap)
+
+#define MLX5_VFIO_CAP64_FLOWTABLE(mdev, cap) \
+	DEVX_GET64(flow_table_nic_cap, (mdev)->caps.hca_cur[MLX5_CAP_FLOW_TABLE], cap)
+
+#define MLX5_VFIO_CAP_FLOWTABLE_MAX(mdev, cap) \
+    DEVX_GET(flow_table_nic_cap, mdev->caps.hca_max[MLX5_CAP_FLOW_TABLE], cap)
+
+#define MLX5_VFIO_CAP_FLOWTABLE_NIC_RX(mdev, cap) \
+	MLX5_VFIO_CAP_FLOWTABLE(mdev, flow_table_properties_nic_receive.cap)
+
+#define MLX5_VFIO_CAP_FLOWTABLE_NIC_RX_MAX(mdev, cap) \
+	MLX5_VFIO_CAP_FLOWTABLE_MAX(mdev, flow_table_properties_nic_receive.cap)
+
+#define MLX5_VFIO_CAP_FLOWTABLE_NIC_TX(mdev, cap) \
+	MLX5_VFIO_CAP_FLOWTABLE(mdev, flow_table_properties_nic_transmit.cap)
+
+#define MLX5_VFIO_CAP_FLOWTABLE_NIC_TX_MAX(mdev, cap) \
+	MLX5_VFIO_CAP_FLOWTABLE_MAX(mdev, flow_table_properties_nic_transmit.cap)
+
 struct mlx5_vfio_context;
 
 struct mlx5_reg_host_endianness {
@@ -279,6 +338,15 @@ struct mlx5_vfio_health_state {
 	uint32_t miss_counter;
 };
 
+
+struct mlx5_dm_internal {
+	/* protect access to icm bitmask */
+	pthread_mutex_t lock;
+	unsigned long *steering_sw_icm_alloc_blocks;
+	unsigned long *header_modify_sw_icm_alloc_blocks;
+	unsigned long *header_modify_pattern_sw_icm_alloc_blocks;
+};
+
 struct mlx5_vfio_context {
 	struct verbs_context vctx;
 	int container_fd;
@@ -304,6 +372,7 @@ struct mlx5_vfio_context {
 	struct mlx5_dv_context_ops *dv_ctx_ops;
 	int *msix_fds;
 	pthread_mutex_t msix_fds_lock;
+	struct mlx5_dm_internal dm;
 };
 
 #define MLX5_MAX_DESTROY_INBOX_SIZE_DW	DEVX_ST_SZ_DW(delete_fte_in)
diff --git a/providers/mlx5/mlx5_vfio_dm.c b/providers/mlx5/mlx5_vfio_dm.c
new file mode 100644
index 00000000..a5c8b917
--- /dev/null
+++ b/providers/mlx5/mlx5_vfio_dm.c
@@ -0,0 +1,429 @@
+
+#include <config.h>
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <unistd.h>
+#include <sys/time.h>
+#include <errno.h>
+#include <sys/stat.h>
+#include <fcntl.h>
+#include <sys/mman.h>
+#include <string.h>
+#include <sys/param.h>
+#include <linux/vfio.h>
+#include <sys/eventfd.h>
+#include <sys/ioctl.h>
+#include <poll.h>
+#include <util/mmio.h>
+
+#include <ccan/array_size.h>
+
+#include "mlx5dv.h"
+#include "mlx5_vfio.h"
+#include "mlx5.h"
+#include "mlx5_ifc.h"
+
+#define MLX5_LOG_SW_ICM_BLOCK_SIZE(ctx) \
+	(MLX5_VFIO_CAP_DEV_MEM(ctx, log_sw_icm_alloc_granularity))
+#define MLX5_SW_ICM_BLOCK_SIZE(ctx) (1UL << MLX5_LOG_SW_ICM_BLOCK_SIZE(ctx))
+#define DIV_ROUND_UP_ULL(x, y) \
+	((unsigned long long)(((unsigned long long)x + (unsigned long long)y - 1) / (unsigned long long)y))
+
+
+
+int mlx5_vfio_dm_init(struct mlx5_vfio_context *ctx)
+{
+	uint64_t header_modify_pattern_icm_blocks = 0;
+	uint64_t header_modify_icm_blocks = 0;
+	uint64_t steering_icm_blocks = 0;
+	struct mlx5_dm_internal *dm = &ctx->dm;
+	bool support_v2;
+	int ret;
+
+	if (!(MLX5_VFIO_CAP_GEN_64(ctx, general_obj_types) &
+		  MLX5_GENERAL_OBJ_TYPES_CAP_SW_ICM))
+		return -ENOTSUP;
+
+	pthread_mutex_init(&ctx->dm.lock, NULL);
+
+	ret = mlx5_vfio_get_caps(ctx, MLX5_CAP_DEV_MEM);
+	if (ret)
+		return ret;
+
+	ret = mlx5_vfio_get_caps(ctx, MLX5_CAP_FLOW_TABLE);
+	if (ret)
+		return ret;
+
+	if (MLX5_VFIO_CAP64_DEV_MEM(ctx, steering_sw_icm_start_address)) {
+		steering_icm_blocks =
+			BIT(MLX5_VFIO_CAP_DEV_MEM(ctx, log_steering_sw_icm_size) -
+			    MLX5_LOG_SW_ICM_BLOCK_SIZE(ctx));
+
+		dm->steering_sw_icm_alloc_blocks =
+			bitmap_alloc0(steering_icm_blocks);
+		if (!dm->steering_sw_icm_alloc_blocks)
+			goto err_steering;
+	}
+
+	if (MLX5_VFIO_CAP64_DEV_MEM(ctx, header_modify_sw_icm_start_address)) {
+		header_modify_icm_blocks =
+			BIT(MLX5_VFIO_CAP_DEV_MEM(ctx, log_header_modify_sw_icm_size) -
+			    MLX5_LOG_SW_ICM_BLOCK_SIZE(ctx));
+
+		dm->header_modify_sw_icm_alloc_blocks =
+			bitmap_alloc0(header_modify_icm_blocks);
+		if (!dm->header_modify_sw_icm_alloc_blocks)
+			goto err_modify_hdr;
+	}
+
+	support_v2 = MLX5_VFIO_CAP_FLOWTABLE_NIC_RX(ctx, sw_owner_v2) &&
+		     MLX5_VFIO_CAP_FLOWTABLE_NIC_TX(ctx, sw_owner_v2) &&
+		     MLX5_VFIO_CAP64_DEV_MEM(ctx, header_modify_pattern_sw_icm_start_address);
+
+	if (support_v2) {
+		header_modify_pattern_icm_blocks =
+			BIT(MLX5_VFIO_CAP_DEV_MEM(ctx, log_header_modify_pattern_sw_icm_size) -
+			    MLX5_LOG_SW_ICM_BLOCK_SIZE(ctx));
+
+		dm->header_modify_pattern_sw_icm_alloc_blocks =
+			bitmap_alloc0(header_modify_pattern_icm_blocks);
+		if (!dm->header_modify_pattern_sw_icm_alloc_blocks)
+			goto err_pattern;
+	}
+
+	return 0;
+
+err_pattern:
+	free(dm->header_modify_sw_icm_alloc_blocks);
+
+err_modify_hdr:
+	free(dm->steering_sw_icm_alloc_blocks);
+
+err_steering:
+	return -ENOMEM;
+}
+
+static int mlx5_dm_sw_icm_alloc(struct mlx5_vfio_context *ctx, int type,
+			 uint64_t length, uint32_t log_alignment,
+			 uintptr_t *addr, uint32_t *obj_id)
+{
+	uint32_t num_blocks = DIV_ROUND_UP_ULL(length, MLX5_SW_ICM_BLOCK_SIZE(ctx));
+	uint32_t out[DEVX_ST_SZ_DW(general_obj_out_cmd_hdr)] = {};
+	uint32_t in[DEVX_ST_SZ_DW(create_sw_icm_in)] = {};
+	struct mlx5_dm_internal *dm = &ctx->dm;
+	unsigned long *block_map;
+	uint64_t icm_start_addr;
+	uint32_t log_icm_size;
+	uint64_t align_mask;
+	uint32_t max_blocks;
+	uint64_t block_idx;
+	void *sw_icm;
+	int ret;
+
+	if (!length || (length & (length - 1)) ||
+	    length & (MLX5_SW_ICM_BLOCK_SIZE(ctx) - 1))
+		return -EINVAL;
+
+	DEVX_SET(general_obj_in_cmd_hdr, in, opcode,
+		 MLX5_CMD_OP_CREATE_GENERAL_OBJECT);
+	DEVX_SET(general_obj_in_cmd_hdr, in, obj_type, MLX5_OBJ_TYPE_SW_ICM);
+
+	switch (type) {
+	case MLX5DV_DM_TYPE_STEERING_SW_ICM:
+		icm_start_addr = MLX5_VFIO_CAP64_DEV_MEM(ctx, steering_sw_icm_start_address);
+		log_icm_size = MLX5_VFIO_CAP_DEV_MEM(ctx, log_steering_sw_icm_size);
+		block_map = dm->steering_sw_icm_alloc_blocks;
+		break;
+	case MLX5DV_DM_TYPE_HEADER_MODIFY_SW_ICM:
+		icm_start_addr = MLX5_VFIO_CAP64_DEV_MEM(ctx, header_modify_sw_icm_start_address);
+		log_icm_size = MLX5_VFIO_CAP_DEV_MEM(ctx,
+						log_header_modify_sw_icm_size);
+		block_map = dm->header_modify_sw_icm_alloc_blocks;
+		break;
+	case MLX5DV_DM_TYPE_HEADER_MODIFY_PATTERN_SW_ICM:
+		icm_start_addr = MLX5_VFIO_CAP64_DEV_MEM(ctx,
+						    header_modify_pattern_sw_icm_start_address);
+		log_icm_size = MLX5_VFIO_CAP_DEV_MEM(ctx,
+						log_header_modify_pattern_sw_icm_size);
+		block_map = dm->header_modify_pattern_sw_icm_alloc_blocks;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	if (!block_map)
+		return -EOPNOTSUPP;
+
+	max_blocks = BIT(log_icm_size - MLX5_LOG_SW_ICM_BLOCK_SIZE(ctx));
+
+	if (log_alignment < MLX5_LOG_SW_ICM_BLOCK_SIZE(ctx))
+		log_alignment = MLX5_LOG_SW_ICM_BLOCK_SIZE(ctx);
+	align_mask = BIT(log_alignment - MLX5_LOG_SW_ICM_BLOCK_SIZE(ctx)) - 1;
+
+	pthread_mutex_lock(&dm->lock);
+
+
+	unsigned long start = 0;
+again:
+	block_idx = bitmap_find_free_region_start(block_map, start, max_blocks, num_blocks);
+	block_idx = (block_idx + align_mask) & ~align_mask;
+	if (block_idx < max_blocks &&
+		bitmap_find_free_region_start(block_map, block_idx, max_blocks, num_blocks) != block_idx) {
+		start = block_idx;
+		goto again;
+	}
+
+	if (block_idx < max_blocks)
+		bitmap_set_bit(block_map, block_idx);
+
+	pthread_mutex_unlock(&dm->lock);
+
+	if (block_idx >= max_blocks)
+		return -ENOMEM;
+
+	sw_icm = DEVX_ADDR_OF(create_sw_icm_in, in, sw_icm);
+	icm_start_addr += block_idx << MLX5_LOG_SW_ICM_BLOCK_SIZE(ctx);
+	DEVX_SET64(sw_icm, sw_icm, sw_icm_start_addr,
+		   icm_start_addr);
+	DEVX_SET(sw_icm, sw_icm, log_sw_icm_size, ilog32(length));
+
+	ret = mlx5_vfio_cmd_exec(ctx, (void *)in, sizeof(in), out, sizeof(out), 0);
+	if (ret) {
+		pthread_mutex_lock(&dm->lock);
+		bitmap_clear_bit(block_map,
+			     block_idx);
+		pthread_mutex_unlock(&dm->lock);
+
+		return ret;
+	}
+
+	*addr = icm_start_addr;
+	*obj_id = DEVX_GET(general_obj_out_cmd_hdr, out, obj_id);
+
+	return 0;
+}
+
+struct ibv_dm *mlx5_vfio_alloc_dm(struct ibv_context *ibctx,
+				   struct ibv_alloc_dm_attr *dm_attr,
+				   struct mlx5dv_alloc_dm_attr *mlx5_dm_attr)
+{
+	struct mlx5_dm *dm;
+	struct mlx5_vfio_context *ctx = to_mvfio_ctx(ibctx);
+	uint32_t obj_id;
+	int ret;
+
+	dm = calloc(1, sizeof(*dm));
+	if (!dm) {
+		errno = ENOMEM;
+		return NULL;
+	}
+
+	ret = mlx5_dm_sw_icm_alloc(ctx, mlx5_dm_attr->type, dm_attr->length,
+		                       dm_attr->log_align_req, &dm->remote_va, &obj_id);
+	if (ret) {
+		free(dm);
+		errno = ret;
+		return NULL;
+	}
+
+	dm->verbs_dm.dm.context = ibctx;
+	dm->length = dm_attr->length;
+	dm->verbs_dm.handle = obj_id;
+	return &dm->verbs_dm.dm;
+}
+
+enum {
+	MLX5_DM_ALLOWED_ACCESS = IBV_ACCESS_LOCAL_WRITE		|
+				 IBV_ACCESS_REMOTE_WRITE	|
+				 IBV_ACCESS_REMOTE_READ		|
+				 IBV_ACCESS_REMOTE_ATOMIC	|
+				 IBV_ACCESS_ZERO_BASED		|
+				 IBV_ACCESS_OPTIONAL_RANGE
+};
+
+static void set_mkc_access_pd_addr_fields(void *mkc, int acc, uint64_t start_addr,
+					  struct ibv_pd *pd)
+{
+	struct mlx5_pd *mpd = to_mpd(pd);
+
+	DEVX_SET(mkc, mkc, a, !!(acc & IBV_ACCESS_REMOTE_ATOMIC));
+	DEVX_SET(mkc, mkc, rw, !!(acc & IBV_ACCESS_REMOTE_WRITE));
+	DEVX_SET(mkc, mkc, rr, !!(acc & IBV_ACCESS_REMOTE_READ));
+	DEVX_SET(mkc, mkc, lw, !!(acc & IBV_ACCESS_LOCAL_WRITE));
+	DEVX_SET(mkc, mkc, lr, 1);
+	/* Application is responsible to set based on caps */
+	DEVX_SET(mkc, mkc, relaxed_ordering_write,
+		 !!(acc & IBV_ACCESS_RELAXED_ORDERING));
+	DEVX_SET(mkc, mkc, relaxed_ordering_read,
+		 !!(acc & IBV_ACCESS_RELAXED_ORDERING));
+	DEVX_SET(mkc, mkc, pd, mpd->pdn);
+	DEVX_SET(mkc, mkc, qpn, 0xffffff);
+	DEVX_SET64(mkc, mkc, start_addr, start_addr);
+}
+
+static inline uint32_t mlx5_idx_to_mkey(uint32_t mkey_idx)
+{
+	return mkey_idx << 8;
+}
+
+
+static int mlx5_core_create_mkey(struct mlx5_vfio_context *ctx, uint32_t *mkey, uint32_t *in,
+			  int inlen)
+{
+	uint32_t lout[DEVX_ST_SZ_DW(create_mkey_out)] = {};
+	uint32_t mkey_index;
+	int err;
+
+	DEVX_SET(create_mkey_in, in, opcode, MLX5_CMD_OP_CREATE_MKEY);
+
+	err = mlx5_vfio_cmd_exec(ctx, in, inlen, lout, sizeof(lout), 0);
+	if (err)
+		return err;
+
+	mkey_index = DEVX_GET(create_mkey_out, lout, mkey_index);
+	*mkey = DEVX_GET(create_mkey_in, in, memory_key_mkey_entry.mkey_7_0) |
+		mlx5_idx_to_mkey(mkey_index);
+
+	return 0;
+}
+
+
+static void assign_mkey_variant(struct mlx5_vfio_context *ctx, uint32_t *mkey, uint32_t *in)
+{
+	struct mlx5_vfio_device *dev = to_mvfio_dev(ctx->vctx.context.device);
+
+	uint8_t key = atomic_fetch_add(&dev->mkey_var, 1);
+	void *mkc;
+
+	mkc = DEVX_ADDR_OF(create_mkey_in, in, memory_key_mkey_entry);
+	DEVX_SET(mkc, mkc, mkey_7_0, key);
+	*mkey = key;
+}
+
+
+static int mlx5_ib_create_mkey(struct mlx5_vfio_context *ctx,
+			       uint32_t *mkey, uint32_t *in, int inlen)
+{
+	int ret;
+
+	assign_mkey_variant(ctx, mkey, in);
+	ret = mlx5_core_create_mkey(ctx, mkey, in, inlen);
+
+	return ret;
+}
+
+static int mlx5_ib_get_dm_mr(struct ibv_pd *pd, uint64_t start_addr,
+				       uint64_t length, int acc, int mode, uint32_t *mkey_out)
+{
+	struct mlx5_vfio_context *ctx = to_mvfio_ctx(pd->context);
+
+	int inlen = DEVX_ST_SZ_BYTES(create_mkey_in);
+	// struct mlx5_ib_mr *mr;
+	void *mkc;
+	uint32_t *in;
+	int err;
+
+	uint32_t mkey;
+
+	// mr = kzalloc(sizeof(*mr), GFP_KERNEL);
+	// if (!mr)
+	// 	return ERR_PTR(-ENOMEM);
+
+	in = calloc(1, inlen);
+	if (!in) {
+		err = -ENOMEM;
+		goto err_free;
+	}
+
+	mkc = DEVX_ADDR_OF(create_mkey_in, in, memory_key_mkey_entry);
+
+	DEVX_SET(mkc, mkc, access_mode_1_0, mode & 0x3);
+	DEVX_SET(mkc, mkc, access_mode_4_2, (mode >> 2) & 0x7);
+	DEVX_SET64(mkc, mkc, len, length);
+	set_mkc_access_pd_addr_fields(mkc, acc, start_addr, pd);
+
+	err = mlx5_ib_create_mkey(ctx, &mkey, in, inlen);
+	if (err)
+		goto err_in;
+
+	free(in);
+
+	// set_mr_fields(dev, mr, length, acc, start_addr);
+	*mkey_out = mkey;
+	return 0;
+
+err_in:
+	free(in);
+
+err_free:
+// 	kfree(mr);
+
+	return err;
+}
+
+static int ibv_cmd_reg_dm_mr_internal(struct ibv_pd *pd, struct mlx5_dm *dm,
+		      uint64_t offset, size_t length,
+		      unsigned int access, struct verbs_mr *vmr)
+{
+
+	uint32_t lkey;
+	int ret;
+
+	/*
+	 * DM MRs are always 0 based since the mmap pointer, if it exists, is
+	 * hidden from the user.
+	 */
+	if (!(access & IBV_ACCESS_ZERO_BASED)) {
+		errno = EINVAL;
+		return errno;
+	}
+
+	ret = mlx5_ib_get_dm_mr(pd, dm->remote_va, length,
+				 access, MLX5_MKC_ACCESS_MODE_SW_ICM, &lkey);
+	if (ret)
+		return errno;
+
+	vmr->ibv_mr.context = pd->context;
+	vmr->ibv_mr.lkey = lkey;
+	vmr->ibv_mr.rkey = lkey;
+	vmr->ibv_mr.length = length;
+	vmr->ibv_mr.pd = pd;
+	vmr->ibv_mr.addr = NULL;
+	vmr->mr_type  = IBV_MR_TYPE_MR;
+
+	return 0;
+}
+
+
+struct ibv_mr *mlx5_vfio_reg_dm_mr(struct ibv_pd *pd, struct ibv_dm *ibdm,
+			      uint64_t dm_offset, size_t length,
+			      unsigned int acc)
+{
+	struct mlx5_dm *dm = container_of(ibdm, struct mlx5_dm, verbs_dm.dm);
+	struct mlx5_mr *mr;
+	int ret;
+
+	if (acc & ~MLX5_DM_ALLOWED_ACCESS) {
+		errno = EINVAL;
+		return NULL;
+	}
+
+	mr = calloc(1, sizeof(*mr));
+	if (!mr) {
+		errno = ENOMEM;
+		return NULL;
+	}
+
+	ret = ibv_cmd_reg_dm_mr_internal(pd, dm, dm_offset, length, acc,
+				&mr->vmr);
+	if (ret) {
+		free(mr);
+		return NULL;
+	}
+
+	mr->alloc_flags = acc;
+	mr->vmr.ibv_mr.context = pd->context;
+
+	return &mr->vmr.ibv_mr;
+}
diff --git a/providers/mlx5/mlx5_vfio_dr.c b/providers/mlx5/mlx5_vfio_dr.c
new file mode 100644
index 00000000..7fcd8d13
--- /dev/null
+++ b/providers/mlx5/mlx5_vfio_dr.c
@@ -0,0 +1,154 @@
+#include <config.h>
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <unistd.h>
+#include <sys/time.h>
+#include <errno.h>
+#include <sys/stat.h>
+#include <fcntl.h>
+#include <sys/mman.h>
+#include <string.h>
+#include <sys/param.h>
+#include <linux/vfio.h>
+#include <sys/eventfd.h>
+#include <sys/ioctl.h>
+#include <poll.h>
+#include <util/mmio.h>
+
+#include <ccan/array_size.h>
+
+#include "mlx5dv.h"
+#include "mlx5_vfio.h"
+#include "mlx5.h"
+#include "mlx5_ifc.h"
+
+static int mlx5_port_type_to_verbs(int port_type_cap)
+{
+    switch (port_type_cap) {
+    case MLX5_CAP_PORT_TYPE_IB:
+        return IBV_LINK_LAYER_INFINIBAND;
+    case MLX5_CAP_PORT_TYPE_ETH:
+        return IBV_LINK_LAYER_ETHERNET;
+    default:
+        return IBV_LINK_LAYER_UNSPECIFIED;
+    }
+}
+
+// For now we only return the value of link_layer
+int mlx5_vfio_query_port(struct ibv_context *ibctx, uint8_t port,
+		     struct ibv_port_attr *attr)
+{
+	struct mlx5_vfio_context *ctx = to_mvfio_ctx(ibctx);
+
+	assert(port == 1);
+
+	attr->link_layer = mlx5_port_type_to_verbs(
+		MLX5_VFIO_CAP_GEN(ctx, port_type));
+	return 0;
+}
+
+// For now we only return:
+// orig_attr.fw_ver
+// phys_port_cnt_ex
+int mlx5_vfio_query_device_ex(struct ibv_context *ibctx,
+			 const struct ibv_query_device_ex_input *input,
+			 struct ibv_device_attr_ex *attr,
+			 size_t attr_size)
+{
+	struct mlx5_vfio_context *ctx = to_mvfio_ctx(ibctx);
+	struct mlx5_init_seg *iseg = ctx->bar_map;
+	struct ibv_device_attr *a;
+
+	a = &attr->orig_attr;
+
+	snprintf(a->fw_ver, sizeof(a->fw_ver), "%d.%d.%04d",
+		be32toh(mmio_read32_be(&iseg->fw_rev)) & 0xffff,
+		be32toh(mmio_read32_be(&iseg->fw_rev)) >> 16,
+		be32toh(mmio_read32_be(&iseg->cmdif_rev_fw_sub)) & 0xffff);
+
+	attr->phys_port_cnt_ex = max(MLX5_VFIO_CAP_GEN(ctx, num_ports),
+                        MLX5_VFIO_CAP_GEN(ctx, num_vhca_ports));
+
+	return 0;
+}
+
+struct ibv_cq *mlx5_vfio_create_cq(struct ibv_context *ibctx, int cqe,
+			     struct ibv_comp_channel *channel,
+			     int comp_vector)
+{
+	int i, ret;
+	uint32_t in[DEVX_ST_SZ_DW(create_cq_in)] = {0};
+	uint32_t out[DEVX_ST_SZ_DW(create_cq_out)] = {0};
+	uint64_t cqe_cnt = roundup_pow_of_two(cqe);
+	void *cq_ctx;
+	void *bufs = NULL;
+	struct mlx5_vfio_cq *vcq = NULL;
+	struct mlx5_vfio_context *ctx = to_mvfio_ctx(ibctx);
+
+	vcq = calloc(1, sizeof(*vcq));
+	if (!vcq) {
+		errno = ENOMEM;
+		return NULL;
+	}
+
+	size_t alloc_len = cqe_cnt * sizeof(struct mlx5_cqe64) + 64;
+	ret = posix_memalign(&bufs, 4096, alloc_len);
+	if (ret) {
+		errno = ENOMEM;
+		goto err;
+	}
+
+	vcq->cq.buf = bufs;
+	vcq->cq.dbrec = bufs + cqe_cnt * sizeof(struct mlx5_cqe64);
+	vcq->cq.cqe_cnt = cqe_cnt;
+	vcq->cq.cqe_size = sizeof(struct mlx5_cqe64);
+	vcq->cq.cq_uar = NULL;
+
+	vcq->mem_reg = mlx5dv_devx_umem_reg(ibctx, bufs, alloc_len, IBV_ACCESS_LOCAL_WRITE);
+	if (!vcq->mem_reg)
+		goto err;
+
+	DEVX_SET(create_cq_in, in, opcode, MLX5_CMD_OP_CREATE_CQ);
+	cq_ctx = DEVX_ADDR_OF(create_cq_in, in, cq_context);
+
+	for (i = 0; i < cqe_cnt; i++)
+		mlx5dv_set_cqe_owner((struct mlx5_cqe64 *)bufs + i, 1);
+
+	DEVX_SET(cqc, cq_ctx, log_cq_size, ilog32(cqe_cnt - 1));
+	DEVX_SET(cqc, cq_ctx, uar_page, ctx->eqs_uar.uarn);
+
+	DEVX_SET(cqc, cq_ctx, c_eqn, ctx->async_eq.eqn);
+
+	DEVX_SET(create_cq_in, in, cq_umem_valid, 1);
+	DEVX_SET(create_cq_in, in, cq_umem_id, vcq->mem_reg->umem_id);
+	DEVX_SET64(create_cq_in, in, cq_umem_offset, 0);
+
+	DEVX_SET(cqc, cq_ctx, dbr_umem_valid, 1);
+	DEVX_SET(cqc, cq_ctx, dbr_umem_id, vcq->mem_reg->umem_id);
+	DEVX_SET64(cqc, cq_ctx, dbr_addr, cqe_cnt * sizeof(struct mlx5_cqe64));
+
+	vcq->obj = ctx->dv_ctx_ops->devx_obj_create(ibctx, in, sizeof(in), out, sizeof(out));
+	if (!vcq->obj)
+		goto err;
+
+	vcq->cq.cqn = DEVX_GET(create_cq_out, out, cqn);
+
+	return &vcq->cq_handle;
+
+err:
+
+	if (vcq->obj)
+		ctx->dv_ctx_ops->devx_obj_destroy(vcq->obj);
+
+	if (vcq->mem_reg)
+		ctx->dv_ctx_ops->devx_umem_dereg(vcq->mem_reg);
+
+	if (vcq->cq.buf)
+		free(vcq->cq.buf);
+
+	free(vcq);
+
+	return NULL;
+}
+
diff --git a/providers/mlx5/mlx5dv.h b/providers/mlx5/mlx5dv.h
index 6c1dc965..7371b1a2 100644
--- a/providers/mlx5/mlx5dv.h
+++ b/providers/mlx5/mlx5dv.h
@@ -2218,6 +2218,8 @@ struct mlx5dv_devx_msi_vector {
 	int fd;
 };
 
+extern uint32_t mlx5dv_dr_table_get_id(struct mlx5dv_dr_table *tbl);
+
 struct mlx5dv_devx_msi_vector *
 mlx5dv_devx_alloc_msi_vector(struct ibv_context *ibctx);
 
diff --git a/providers/mlx5/mlx5dv_dr.h b/providers/mlx5/mlx5dv_dr.h
index f3915cb2..e3d47011 100644
--- a/providers/mlx5/mlx5dv_dr.h
+++ b/providers/mlx5/mlx5dv_dr.h
@@ -1038,7 +1038,12 @@ struct dr_domain_info {
 	uint32_t		max_send_size;
 	struct dr_domain_rx_tx	rx;
 	struct dr_domain_rx_tx	tx;
-	struct ibv_device_attr_ex attr;
+	struct {
+		struct {
+			char fw_ver[64];
+		} orig_attr;
+		uint32_t phys_port_cnt_ex;
+	} attr;
 	struct dr_devx_caps	caps;
 	bool			use_mqs;
 };
diff --git a/util/bitmap.c b/util/bitmap.c
index ebbe2557..ba2bac01 100644
--- a/util/bitmap.c
+++ b/util/bitmap.c
@@ -162,3 +162,23 @@ unsigned long bitmap_find_free_region(unsigned long *bmp,
 	return nbits;
 }
 
+unsigned long bitmap_find_free_region_start(unsigned long *bmp,
+					  unsigned long start,
+				      unsigned long nbits,
+				      unsigned long region_size)
+{
+	if (!region_size)
+		return 0;
+
+	for (; start + region_size <= nbits; start++) {
+		if (bitmap_test_bit(bmp, start))
+			continue;
+
+		if (bitmap_is_free_region(bmp, start, region_size))
+			return start;
+	}
+
+	return nbits;
+}
+
+
diff --git a/util/bitmap.h b/util/bitmap.h
index c48706a4..59e6a99e 100644
--- a/util/bitmap.h
+++ b/util/bitmap.h
@@ -27,6 +27,12 @@ unsigned long bitmap_find_free_region(unsigned long *bmp,
 				      unsigned long nbits,
 				      unsigned long region_size);
 
+
+unsigned long bitmap_find_free_region_start(unsigned long *bmp,
+					  unsigned long start,
+				      unsigned long nbits,
+				      unsigned long region_size);
+
 static inline void bitmap_fill(unsigned long *bmp, unsigned long nbits)
 {
 	unsigned long size = BITS_TO_LONGS(nbits) * sizeof(unsigned long);
-- 
2.43.0

